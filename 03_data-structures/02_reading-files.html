<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Stat 585 - Reading files</title>
    <meta charset="utf-8" />
    <meta name="author" content="Heike Hofmann" />
    <script src="libs/header-attrs-2.11.6/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Stat 585 - Reading files
### Heike Hofmann

---


# Text files versus binary files

- text files are all formats that are humanly readable, i.e. we can open the files in a text editor and read the contents

- binary files encode contents in a machine readable form

- What are the pros and cons?



---

# nasa data - binary file


```r
data(nasa, package = "GGally")
dim(nasa)
```

```
## [1] 41472    17
```

```r
saveRDS(nasa, "../data/nasadata.rds")
```

![](images/nasa-binary.png)

---

# nasa data - text file


```r
write.csv(nasa, "../data/nasadata.csv", row.names = FALSE)
```

![](images/nasa-text.png)

---

# Text files and R

- base R supports reading text files, e.g. `read.table(), read.csv(), read.delim()` reads data from  text files  with specified delimiters 

- `write.table()` writes  text files 

- the `readr` package provides similar functionality: `read_csv, read_tsv, read_delim`

- `readr` functions are faster than base R functions, if the whole file is being read at once

- all of the text files have to be highly structured to be readable


---

## Binary files and R

- `saveRDS()` saves a single R object in binary format, use extension `.rds`

- `readRDS()` reads R binary file

- `save()` saves all objects in a binary file (and keeps their names), use extension `.rda` 

- `load()` retrieves these objects (using the same names)

---

## Example


```r
system.time(d1 &lt;- read.csv("../data/nasadata.csv"))
```

```
##    user  system elapsed 
##   0.189   0.005   0.194
```

```r
system.time(d2 &lt;- readRDS("../data/nasadata.rds"))
```

```
##    user  system elapsed 
##   0.018   0.001   0.019
```

speed-up is about factor 10 in favor of binary files


---

# Binary file formats

- No restriction in terms on content, streams of bytes

- Advantage: Generally much smaller files, and with compression even smaller, e.g. `nasadata.csv` is 4.3Mb, `nasadata.rds` is 295Kb

- Disadvantage:  

    - introduce a dependency on software (what if in a future version of the software our old binary file cannot be read anymore?) 
    - potential of dependency on operating system
    - file corruption is not recoverable

---

# Text file formats

- humanly readable does not necessarily mean well-structured or nicely readable

- in R we are often dealing with csv, i.e. column separated values

- sometimes we deal with tsv (separated by tabulator)

- we will look at a few different file formats

---

# JSON

- JSON is short for JavaScript  Object Notation (http://json.org/) 

- it is a lightweight data interchange format, becoming increasingly popular

- Human readable and writable

- Utilized by many web APIs, e.g. tumblr, twitter, ... 


---

# JSON - example 

e.g. result from get query in JSON format:

```
 [{"P0010001":710231,"NAME":"Alaska","state":"02"},
 {"P0010001":4779736,"NAME":"Alabama","state":"01"},
 {"P0010001":2915918,"NAME":"Arkansas","state":"05"},
 {"P0010001":6392017,"NAME":"Arizona","state":"04"},
 {"P0010001":37253956,"NAME":"California","state":"06"}]
```

i.e. vector of key-value format - focus is on individual rows in a data set, whereas R puts emphasis on individual columns (data set is list of vectors).

advantage: enables streaming data, i.e new observations can easily be added as they become available

disadvantage: operations across observations are tricky

---

# package `jsonlite`


The package `jsonlite` (tidyverse package, but not part of the core) has functions `toJSON` and `fromJSON` to transform between JSON data and R objects. 


```r
library(jsonlite)
mtcars[1:3,] %&gt;% toJSON(pretty = TRUE)
```

```
## [
##   {
##     "mpg": 21,
##     "cyl": 6,
##     "disp": 160,
##     "hp": 110,
##     "drat": 3.9,
##     "wt": 2.62,
##     "qsec": 16.46,
##     "vs": 0,
##     "am": 1,
##     "gear": 4,
##     "carb": 4,
##     "_row": "Mazda RX4"
##   },
##   {
##     "mpg": 21,
##     "cyl": 6,
##     "disp": 160,
##     "hp": 110,
##     "drat": 3.9,
##     "wt": 2.875,
##     "qsec": 17.02,
##     "vs": 0,
##     "am": 1,
##     "gear": 4,
##     "carb": 4,
##     "_row": "Mazda RX4 Wag"
##   },
##   {
##     "mpg": 22.8,
##     "cyl": 4,
##     "disp": 108,
##     "hp": 93,
##     "drat": 3.85,
##     "wt": 2.32,
##     "qsec": 18.61,
##     "vs": 1,
##     "am": 1,
##     "gear": 4,
##     "carb": 1,
##     "_row": "Datsun 710"
##   }
## ]
```

---
class: inverse
# Your Turn - Reading JSON tuples

The Census Bureau provides access to some of its data through an API, which returns json (like) data.

The url `https://api.census.gov/data/2010/surname?get=NAME,COUNT&amp;RANK=1:100` returns values for surname and counts for the top 100 rank surnames of the 2010 surname table.

```
[["NAME","COUNT","RANK"],
["ADAMS","427865","42"],
["ALLEN","482607","33"],
["ALVAREZ","233983","92"],
["ANDERSON","784404","15"],
["BAILEY","277845","72"],
["BAKER","419586","44"],
...
]
```

Change the above call to include additional data on demographics (see [variables for surname data](https://api.census.gov/data/2010/surname/variables.html)) and read it into your R session.  

Is your last name included? At what rank? what is the change in rank since 2000?

---


```r
query &lt;- "https://api.census.gov/data/2010/surname?get=NAME,COUNT,PCTWHITE,PCTBLACK,PCTHISPANIC,PCTAPI&amp;RANK=1:100"

surnames &lt;- jsonlite::fromJSON(query)

head(surnames, 10)
```

```
##       [,1]       [,2]      [,3]       [,4]       [,5]          [,6]     [,7]  
##  [1,] "NAME"     "COUNT"   "PCTWHITE" "PCTBLACK" "PCTHISPANIC" "PCTAPI" "RANK"
##  [2,] "ADAMS"    "427865"  "74.02"    "19.9"     "2.57"        "0.56"   "42"  
##  [3,] "ALLEN"    "482607"  "67.59"    "26.17"    "2.47"        "0.54"   "33"  
##  [4,] "ALVAREZ"  "233983"  "5.18"     "0.6"      "92.45"       "1.16"   "92"  
##  [5,] "ANDERSON" "784404"  "75.17"    "18.93"    "2.44"        "0.61"   "15"  
##  [6,] "BAILEY"   "277845"  "72.45"    "22"       "2.28"        "0.5"    "72"  
##  [7,] "BAKER"    "419586"  "79.83"    "14.44"    "2.28"        "0.56"   "44"  
##  [8,] "BENNETT"  "247599"  "76.56"    "17.53"    "2.5"         "0.53"   "86"  
##  [9,] "BROOKS"   "251663"  "60.22"    "33.47"    "2.48"        "0.48"   "82"  
## [10,] "BROWN"    "1437026" "57.95"    "35.6"     "2.52"        "0.51"   "4"
```

result is a matrix - it will need some work to turn into a data frame
---

# Navel gazing




```r
url &lt;- "https://api.census.gov/data/%s/surname?get=NAME,COUNT,RANK,PCTWHITE,PCTBLACK,PCTAPI,PCTHISPANIC&amp;%s"
studentnames &lt;- paste("NAME=",students, sep="", collapse = "&amp;")

us2010 &lt;- jsonlite::fromJSON(txt=sprintf(url,  2010, studentnames))
us2000 &lt;- jsonlite::fromJSON(sprintf(url,  2000, studentnames))

us2000
```

```
##      [,1]     [,2]    [,3]    [,4]       [,5]       [,6]     [,7]         
## [1,] "NAME"   "COUNT" "RANK"  "PCTWHITE" "PCTBLACK" "PCTAPI" "PCTHISPANIC"
## [2,] "AKBARI" "523"   "39560" "61.95"    "(S)"      "14.72"  "2.29"       
## [3,] "GUO"    "6058"  "5287"  "0.91"     "(S)"      "97.59"  "0.4"        
## [4,] "PANG"   "6627"  "4865"  "4.04"     "0.36"     "88.47"  "1.77"       
##      [,8]    
## [1,] "NAME"  
## [2,] "AKBARI"
## [3,] "GUO"   
## [4,] "PANG"
```

```r
us2010
```

```
##      [,1]     [,2]    [,3]    [,4]       [,5]       [,6]     [,7]         
## [1,] "NAME"   "COUNT" "RANK"  "PCTWHITE" "PCTBLACK" "PCTAPI" "PCTHISPANIC"
## [2,] "AKBARI" "807"   "29309" "59.23"    "0.99"     "17.6"   "2.85"       
## [3,] "GUO"    "12048" "2975"  "1.1"      "0.32"     "97.77"  "0.17"       
## [4,] "PANG"   "7642"  "4645"  "3.93"     "0.48"     "86.97"  "2.39"       
##      [,8]    
## [1,] "NAME"  
## [2,] "AKBARI"
## [3,] "GUO"   
## [4,] "PANG"
```

---

# HTML FILES

- A lot of data is available online in the form of html tables

- Extracting the data requires recognizing the html table format, and stripping off the html

- Packages such as `xml`, `rvest`, ... helps with this

---

# HTML FILES

  Pulling election results off the web...


```r
library(rvest)
url &lt;- "https://www.nytimes.com/interactive/2020/11/03/us/elections/results-iowa-senate.html"
doc &lt;- read_html(url)
tables &lt;- html_table(doc, fill=TRUE)
head(tables[[2]][,-(3:4)])
```

```
## # A tibble: 6 Ã— 4
##   County        Margin         `Total votes` Absentee
##   &lt;chr&gt;         &lt;chr&gt;          &lt;chr&gt;         &lt;chr&gt;   
## 1 Johnson       Greenfield +40 82,591        59,748  
## 2 Dubuque       Ernst +1.1     53,043        33,820  
## 3 Pottawattamie Ernst +14      45,033        27,059  
## 4 Woodbury      Ernst +12      44,472        27,028  
## 5 Des Moines    Ernst +0.88    19,587        12,534  
## 6 Marshall      Ernst +5       17,851        11,286
```


---
  
# Other binary formats and R
  
  - Packages `foreign` or `haven`: Data export/import for other (statistical) software: Stata, Epi, Octave, SPSS, Systat, SAS

- Package `readxl` import/export with Excel spreadsheets
e.g. web index data at http://www.visualizing.org/datasets/web-index-2013


---
  
# Why do we need to access all these formats? 
  
  - To solve a problem, may need to collate data from multiple sources

- Rearranging and merging data from different sources helps to pull together the data necessary to solve the problem


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
